(window.webpackJsonp=window.webpackJsonp||[]).push([[160],{489:function(a,t,e){"use strict";e.r(t);var r=e(7),s=Object(r.a)({},(function(){var a=this,t=a._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("p",[a._v("项目基于 Spring AI 提供的 "),t("a",{attrs:{href:"https://github.com/spring-projects/spring-ai/tree/main/models/spring-ai-ollama",target:"_blank",rel:"noopener noreferrer"}},[t("code",[a._v("spring-ai-ollama")]),t("OutboundLink")],1),a._v("，实现 Llama 的接入：")]),a._v(" "),t("table",[t("thead",[t("tr",[t("th",[a._v("功能")]),a._v(" "),t("th",[a._v("模型")]),a._v(" "),t("th",[a._v("Spring AI 客户端")])])]),a._v(" "),t("tbody",[t("tr",[t("td",[a._v("AI 对话")]),a._v(" "),t("td",[a._v("llama3、llama2")]),a._v(" "),t("td",[t("a",{attrs:{href:"https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("Ollama Chat"),t("OutboundLink")],1)])]),a._v(" "),t("tr",[t("td",[a._v("AI 绘画")]),a._v(" "),t("td",[t("a",{attrs:{href:"https://new.qq.com/rain/a/20240420A005CK00",target:"_blank",rel:"noopener noreferrer"}},[a._v("llama3 支持生成图片"),t("OutboundLink")],1)]),a._v(" "),t("td",[a._v("暂未支持")])])])]),a._v(" "),t("h2",{attrs:{id:"_1-申请密钥"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-申请密钥"}},[a._v("#")]),a._v(" 1. 申请密钥")]),a._v(" "),t("p",[a._v("Llama 是 Meta 开源的模型，所以可以私有化部署。")]),a._v(" "),t("h3",{attrs:{id:"_1-1-私有化部署"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-私有化部署"}},[a._v("#")]),a._v(" 1.1 私有化部署")]),a._v(" "),t("p",[a._v("① 访问 "),t("a",{attrs:{href:"https://ollama.ai/download",target:"_blank",rel:"noopener noreferrer"}},[a._v("Ollama 官网"),t("OutboundLink")],1),a._v("，下载对应系统 Ollama 客户端，然后安装。")]),a._v(" "),t("p",[a._v("② 安装完成后，在命令中执行 "),t("code",[a._v("ollama run llama3")]),a._v(" 命令，一键部署 "),t("code",[a._v("llama3")]),a._v(" 模型。")]),a._v(" "),t("hr"),a._v(" "),t("p",[a._v("部署完成后，可以在我们系统的 [AI 大模型 -> 控制台 -> API 密钥] 菜单，进行密钥的配置。需要填写“密钥” + “自定义 API URL”（因为让 Spring AI 使用该地址）。如下图所示：")]),a._v(" "),t("p",[t("img",{attrs:{src:"/img/AI%E6%89%8B%E5%86%8C/%E6%A8%A1%E5%9E%8B%E6%8E%A5%E5%85%A5/Ollama-%E5%AF%86%E9%92%A5.png",alt:"私有的密钥配置"}})]),a._v(" "),t("h2",{attrs:{id:"_2-模型配置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-模型配置"}},[a._v("#")]),a._v(" 2. 模型配置")]),a._v(" "),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[a._v("友情提示：")]),a._v(" "),t("p",[a._v("目前 "),t("code",[a._v("ai_model")]),a._v(" 表中，已经预置了一些模型，可以直接使用！！！")])]),a._v(" "),t("h3",{attrs:{id:"_2-1-ai-对话"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-ai-对话"}},[a._v("#")]),a._v(" 2.1 AI 对话")]),a._v(" "),t("p",[a._v("使用 "),t("RouterLink",{attrs:{to:"/ai/chat/"}},[a._v("《AI 对话》")]),a._v(" 时，需要在 [AI 大模型 -> 控制台 -> 模型配置] 菜单，配置对应的聊天模型。")],1),a._v(" "),t("p",[a._v("配置对应的聊天模型为 "),t("code",[a._v("llama3")]),a._v("，然后它的 "),t("code",[a._v("max_tokens")]),a._v("（回复数 Token 数）填写 4096 即可。")]),a._v(" "),t("h3",{attrs:{id:"_2-2-ai-绘画"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-ai-绘画"}},[a._v("#")]),a._v(" 2.2 AI 绘画")]),a._v(" "),t("p",[a._v("TODO 等待 Ollama ImageModel 客户端！")]),a._v(" "),t("h2",{attrs:{id:"_3-如何使用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-如何使用"}},[a._v("#")]),a._v(" 3. 如何使用？")]),a._v(" "),t("p",[a._v("① 如果你的项目里需要直接通过 "),t("code",[a._v("@Resource")]),a._v(" 注入 OllamaChatModel 等对象，需要把 "),t("code",[a._v("application.yaml")]),a._v(" 配置文件里的 "),t("code",[a._v("spring.ai.ollama")]),a._v(" 配置项，替换成你的！")]),a._v(" "),t("div",{staticClass:"language-YAML extra-class"},[t("pre",{pre:!0,attrs:{class:"language-yaml"}},[t("code",[t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("spring")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("ai")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("ollama")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n      "),t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("base-url")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" http"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("//127.0.0.1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("11434")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 你的私有化部署地址")]),a._v("\n      "),t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("chat")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("model")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" llama3\n")])])]),t("p",[a._v("② 如果你希望使用 [AI 大模型 -> 控制台 -> API 密钥] 菜单的密钥配置，则可以通过 AiModelService 的 "),t("code",[a._v("#getChatModel(...)")]),a._v(" 方法，获取对应的模型对象。")]),a._v(" "),t("hr"),a._v(" "),t("p",[a._v("① 和 ② 这两者的后续使用，就是标准的 Spring AI 客户端的使用，调用对应的方法即可。")]),a._v(" "),t("p",[a._v("另外，LlamaChatModelTests 里有对应的测试用例，可以参考。")])])}),[],!1,null,null,null);t.default=s.exports}}]);